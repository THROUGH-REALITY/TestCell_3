{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "(code: 1073741845). Bad file descriptor (C:\\ci\\zeromq_1602704446950\\work\\src\\epoll.cpp:100). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class GridWorld:\n",
    "\n",
    "    def __init__(self, x_max, y_max):\n",
    "\n",
    "        self.x_max = x_max\n",
    "        self.y_max = y_max\n",
    "        self.filed_type = {\n",
    "            \"N\": 0,  # 通常\n",
    "            \"G\": 1,  # ゴール\n",
    "            \"W\": 2,  # 壁\n",
    "            \"H\": 3,  # 他の人間\n",
    "        }\n",
    "        self.actions = {\n",
    "            \"UP\": 0,\n",
    "            \"DOWN\": 1,\n",
    "            \"LEFT\": 2,\n",
    "            \"RIGHT\": 3\n",
    "        }\n",
    "        self.map = np.zeros((y_max,x_max))\n",
    "        self.map[::2] = 2 \n",
    "        self.map[:, ::2] = 0\n",
    "        self.map[0,0] = 1\n",
    "\n",
    "        self.zero_list = list(zip(*np.where( self.map < 1)))\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "            行動の実行\n",
    "            状態, 報酬、ゴールしたかを返却\n",
    "        \"\"\"\n",
    "        to_x, to_y = copy.deepcopy(self.agent_pos)\n",
    "\n",
    "        # 移動可能かどうかの確認。移動不可能であれば、ポジションはそのままにマイナス報酬\n",
    "        if self._is_possible_action(to_x, to_y, action) == False:\n",
    "            return self.agent_pos, -10, False\n",
    "\n",
    "        if action == self.actions[\"UP\"]:\n",
    "            to_y += -1\n",
    "        elif action == self.actions[\"DOWN\"]:\n",
    "            to_y += 1\n",
    "        elif action == self.actions[\"LEFT\"]:\n",
    "            to_x += -1\n",
    "        elif action == self.actions[\"RIGHT\"]:\n",
    "            to_x += 1\n",
    "\n",
    "        is_goal = self._is_end_episode(to_x, to_y)  # エピソードの終了の確認\n",
    "        reward = self._compute_reward(to_x, to_y)\n",
    "        self.agent_pos = to_x, to_y\n",
    "        return self.agent_pos, reward, is_goal\n",
    "\n",
    "    def _is_end_episode(self, x, y):\n",
    "        \"\"\"\n",
    "            x, yがエピソードの終了かの確認。\n",
    "        \"\"\"\n",
    "        if self.map[y,x] == self.filed_type[\"G\"]: # ゴール\n",
    "            return True\n",
    "        #elif self.map[y][x] == self.filed_type[\"T\"]:    # トラップ\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def _is_wall(self, x, y):\n",
    "        \"\"\"\n",
    "            x, yが壁または人間かどうかの確認\n",
    "        \"\"\"\n",
    "        if self.map[y,x] == self.filed_type[\"W\"]:\n",
    "            return True\n",
    "        elif self.map[y,x] == self.filed_type[\"H\"]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def _is_possible_action(self, x, y, action):\n",
    "        \"\"\"\n",
    "            実行可能な行動かどうかの判定\n",
    "        \"\"\"\n",
    "        to_x = x\n",
    "        to_y = y\n",
    "\n",
    "        if action == self.actions[\"UP\"]:\n",
    "            #print(\"上に行った\")\n",
    "            to_y += -1\n",
    "            #print(to_y,to_x)\n",
    "        elif action == self.actions[\"DOWN\"]:\n",
    "            #print(\"下に行った\")\n",
    "            to_y += 1\n",
    "            #print(to_y,to_x)\n",
    "        elif action == self.actions[\"LEFT\"]:\n",
    "            #print(\"左に行った\")\n",
    "            to_x += -1\n",
    "            #print(to_y,to_x)\n",
    "        elif action == self.actions[\"RIGHT\"]:\n",
    "            #print(\"右に行った\")\n",
    "            to_x += 1\n",
    "            #print(to_y,to_x)\n",
    "\n",
    "        if self.map.shape[0] <= to_y or 0 > to_y:\n",
    "            #print(\"y行き過ぎ\")\n",
    "            return False\n",
    "        elif self.map.shape[1] <= to_x or 0 > to_x:\n",
    "            #print(\"x行き過ぎ\")\n",
    "            return False\n",
    "        elif self._is_wall(to_x, to_y):\n",
    "            #print(\"壁だった\")\n",
    "            #print(to_y,to_x)\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _compute_reward(self, x, y):\n",
    "        if self.map[y,x] == self.filed_type[\"N\"]:\n",
    "            return 0\n",
    "        elif self.map[y,x] == self.filed_type[\"G\"]:\n",
    "            return 100\n",
    "        #elif self.map[y,x] == self.filed_type[\"T\"]:\n",
    "            return -100\n",
    "\n",
    "    def reset(self):\n",
    "        self.agent_pos = self.start_pos\n",
    "        return self.start_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (0, 4), (0, 6), (0, 8), (0, 10), (0, 12), (0, 14), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (2, 0), (2, 2), (2, 4), (2, 6), (2, 8), (2, 10), (2, 12), (2, 14), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (3, 11), (3, 12), (3, 13), (3, 14), (4, 0), (4, 2), (4, 4), (4, 6), (4, 8), (4, 10), (4, 12), (4, 14), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (6, 0), (6, 2), (6, 4), (6, 6), (6, 8), (6, 10), (6, 12), (6, 14), (7, 0), (7, 1), (7, 2), (7, 3), (7, 4), (7, 5), (7, 6), (7, 7), (7, 8), (7, 9), (7, 10), (7, 11), (7, 12), (7, 13), (7, 14), (8, 0), (8, 2), (8, 4), (8, 6), (8, 8), (8, 10), (8, 12), (8, 14), (9, 0), (9, 1), (9, 2), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9), (9, 10), (9, 11), (9, 12), (9, 13), (9, 14), (10, 0), (10, 2), (10, 4), (10, 6), (10, 8), (10, 10), (10, 12), (10, 14), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (11, 10), (11, 11), (11, 12), (11, 13), (11, 14), (12, 0), (12, 2), (12, 4), (12, 6), (12, 8), (12, 10), (12, 12), (12, 14), (13, 0), (13, 1), (13, 2), (13, 3), (13, 4), (13, 5), (13, 6), (13, 7), (13, 8), (13, 9), (13, 10), (13, 11), (13, 12), (13, 13), (13, 14), (14, 0), (14, 2), (14, 4), (14, 6), (14, 8), (14, 10), (14, 12), (14, 14), (15, 0), (15, 1), (15, 2), (15, 3), (15, 4), (15, 5), (15, 6), (15, 7), (15, 8), (15, 9), (15, 10), (15, 11), (15, 12), (15, 13), (15, 14), (16, 0), (16, 2), (16, 4), (16, 6), (16, 8), (16, 10), (16, 12), (16, 14), (17, 0), (17, 1), (17, 2), (17, 3), (17, 4), (17, 5), (17, 6), (17, 7), (17, 8), (17, 9), (17, 10), (17, 11), (17, 12), (17, 13), (17, 14)]\n"
     ]
    }
   ],
   "source": [
    "X_MAX = 15\n",
    "Y_MAX = 18\n",
    "START_X = X_MAX - 1     # 端からスタートさせる\n",
    "START_Y = Y_MAX - 1\n",
    "POPULATION = 2\n",
    "\n",
    "# 定数\n",
    "NB_EPISODE = 1000   # エピソード数\n",
    "EPSILON = .1    # 探索率\n",
    "ALPHA = .1      # 学習率\n",
    "GAMMA = .90     # 割引率\n",
    "ACTIONS = np.arange(4)  # 行動の集合\n",
    "\n",
    "class Summon:\n",
    "\n",
    "    def __init__(self, zero_list, population=2):\n",
    "        self.agents = self.__generate_agents(zero_list, population)\n",
    "\n",
    "    def __generate_agents(self, zero_list, population):\n",
    "        agents = []\n",
    "        for id in range(population):\n",
    "            ini_state = random.choice(zero_list) # 初期状態（エージェントのスタート地点の位置）\n",
    "            agents.append(\n",
    "                QLearningAgent(\n",
    "                    alpha=ALPHA,\n",
    "                    gamma=GAMMA,\n",
    "                    epsilon=EPSILON,\n",
    "                    actions=ACTIONS,\n",
    "                    observation=ini_state))\n",
    "        times = []\n",
    "        self.is_end_episode = False  # エージェントがゴールしてるかどうか？\n",
    "        return agents\n",
    "\n",
    "\n",
    "grid_env = GridWorld(   # grid worldの環境の初期化\n",
    "    x_max=X_MAX,\n",
    "    y_max=Y_MAX,\n",
    "    start_x=START_X,\n",
    "    start_y=START_Y)\n",
    "\n",
    "summon = Summon(\n",
    "    zero_list=grid_env.zero_list,\n",
    "    population= POPULATION)\n",
    "\n",
    "print(grid_env.zero_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    \"\"\"\n",
    "        Q学習 エージェント\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha=.2,\n",
    "            epsilon=.1,\n",
    "            gamma=.99,\n",
    "            actions=None,\n",
    "            observation=None):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.reward_history = []\n",
    "        self.actions = actions\n",
    "        self.observation = observation\n",
    "        self.state = str(observation)\n",
    "        self.ini_state = str(observation)\n",
    "        self.previous_state = None\n",
    "        self.previous_action = None\n",
    "        self.q_values = self._init_q_values()\n",
    "\n",
    "    def _init_q_values(self):\n",
    "        \"\"\"\n",
    "           Q テーブルの初期化\n",
    "        \"\"\"\n",
    "        q_values = {}\n",
    "        q_values[self.state] = np.repeat(0.0, len(self.actions))\n",
    "        return q_values\n",
    "\n",
    "    def init_state(self):\n",
    "        \"\"\"\n",
    "            状態の初期化\n",
    "        \"\"\"\n",
    "        self.previous_state = copy.deepcopy(self.ini_state)\n",
    "        self.state = copy.deepcopy(self.ini_state)\n",
    "        return self.state\n",
    "\n",
    "    def act(self):\n",
    "        # ε-greedy選択\n",
    "        if np.random.uniform() < self.epsilon:  # random行動\n",
    "            action = np.random.randint(0, len(self.q_values[self.state]))\n",
    "        else:   # greedy 行動\n",
    "            action = np.argmax(self.q_values[self.state])\n",
    "\n",
    "        self.previous_action = action\n",
    "        return action\n",
    "\n",
    "    def observe(self, next_state, reward=None):\n",
    "        \"\"\"\n",
    "            次の状態と報酬の観測\n",
    "        \"\"\"\n",
    "        next_state = str(next_state)\n",
    "        if next_state not in self.q_values:  # 始めて訪れる状態であれば\n",
    "            self.q_values[next_state] = np.repeat(0.0, len(self.actions))\n",
    "\n",
    "        self.previous_state = copy.deepcopy(self.state)\n",
    "        self.state = next_state\n",
    "\n",
    "        if reward is not None:\n",
    "            self.reward_history.append(reward)\n",
    "            self.learn(reward)\n",
    "\n",
    "    def learn(self, reward):\n",
    "        \"\"\"\n",
    "            Q値の更新\n",
    "        \"\"\"\n",
    "        q = self.q_values[self.previous_state][self.previous_action]  # Q(s, a)\n",
    "        max_q = max(self.q_values[self.state])  # max Q(s')\n",
    "        # Q(s, a) = Q(s, a) + alpha*(r+gamma*maxQ(s')-Q(s, a))\n",
    "        self.q_values[self.previous_state][self.previous_action] = q + \\\n",
    "            (self.alpha * (reward + (self.gamma * max_q) - q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "for e in range(10):\n",
    "    a.append(False)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12faeb009c2a7d76c7235d866f7e41305be57eb82e3be7400ac68b941d4a74d6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
